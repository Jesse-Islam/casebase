{
    "docs": [
        {
            "location": "/", 
            "text": "casebase: A Statistical Software Tool for Survival Analysis\n\n\nThis software is written in the open source software environment \nR\n. It's main functionality is to fit smooth-in-time parametric hazard functions using case-base sampling \nHanley \n Miettinen (2009)\n. \n\n\nThis approach allows the explicit inclusion of the time variable into the model, which enables the user to fit a wide class of parametric hazard functions. For example, including time linearly recovers the Gompertz hazard, whereas including time logarithmically recovers the Weibull hazard; not including time at all corresponds to the exponential hazard.\n\n\nThe theoretical properties of this approach have been studied in \nSaarela \n Arjas (2015) and Saarela (2015)\n.\n\n\nThe software is still in development mode.\n\n\nInstallation\n\n\nThe software package is available on \nGithub\n and can be installed directly from within \nR\n using the following commands (note: you will need the \ndevtools\n package prior to installing the \ncasebase\n package)\n\n\nlibrary(devtools)\ninstall_github('sahirbhatnagar/casebase')", 
            "title": "Home"
        }, 
        {
            "location": "/#casebase-a-statistical-software-tool-for-survival-analysis", 
            "text": "This software is written in the open source software environment  R . It's main functionality is to fit smooth-in-time parametric hazard functions using case-base sampling  Hanley   Miettinen (2009) .   This approach allows the explicit inclusion of the time variable into the model, which enables the user to fit a wide class of parametric hazard functions. For example, including time linearly recovers the Gompertz hazard, whereas including time logarithmically recovers the Weibull hazard; not including time at all corresponds to the exponential hazard.  The theoretical properties of this approach have been studied in  Saarela   Arjas (2015) and Saarela (2015) .  The software is still in development mode.", 
            "title": "casebase: A Statistical Software Tool for Survival Analysis"
        }, 
        {
            "location": "/#installation", 
            "text": "The software package is available on  Github  and can be installed directly from within  R  using the following commands (note: you will need the  devtools  package prior to installing the  casebase  package)  library(devtools)\ninstall_github('sahirbhatnagar/casebase')", 
            "title": "Installation"
        }, 
        {
            "location": "/smoothhazard/", 
            "text": "Methodological details\n\n\nCase-base sampling was proposed by Hanley \n Miettinen [-@hanley2009fitting] as a way to fit smooth-in-time parametric hazard functions via logistic regression. The main idea, which was first proposed by Mantel [-@mantel1973synthetic] and then later developped by Efron [-@efron1977efficiency], is to sample person-moments, i.e. discrete time points along an subject's follow-up time, in order to construct a base series against which the case series can be compared. \n\n\nThis approach allows the explicit inclusion of the time variable into the model, which enables the user to fit a wide class of parametric hazard functions. For example, including time linearly recovers the Gompertz hazard, whereas including time \nlogarithmically\n recovers the Weibull hazard; not including time at all corresponds to the exponential hazard.\n\n\nThe theoretical properties of this approach have been studied in Saarela \n Arjas [-@saarela2015non] and Saarela [-@saarela2015case].\n\n\nFirst example: Veteran dataset\n\n\nThe first example we discuss uses the well-known \nveteran\n dataset, which is part of the \nsurvival\n package. As we can see below, there is almost no censoring, and therefore we can get a good visual representation of the survival function:\n\n\nlibrary(survival)\n\n\n\n\n## \n## Attaching package: 'survival'\n\n\n\n\n## The following object is masked _by_ '.GlobalEnv':\n## \n##     veteran\n\n\n\n\ndata(veteran)\ntable(veteran$status)\n\n\n\n\n## \n##   0   1 \n##   9 128\n\n\n\n\nevtimes \n- veteran$time[veteran$status == 1]\nhist(evtimes, nclass=30, main='', xlab='Survival time (days)', col='gray90', probability=TRUE)\ntgrid \n- seq(0, 1000, by=10)\nlines(tgrid, dexp(tgrid, rate=1.0/mean(evtimes)), \n      lwd=2, lty=2, col='red')\n\n\n\n\n\n\n\nAs we can see, the empirical survival function ressembles an exponential distribution.\n\n\nEstimating Hazard Function Parametrically\n\n\nWe will first try to estimate the hazard function parametrically using some well-known regression routines. But first, we will reformat the data slightly.\n\n\nveteran$prior \n- factor(veteran$prior, levels = c(0, 10))\nveteran$celltype \n- factor(veteran$celltype, \n                           levels = c('large', 'squamous', 'smallcell', 'adeno'))\nveteran$trt \n- factor(veteran$trt, levels = c(1, 2))\n\n\n\n\nUsing the \neha\n package, we can fit a Weibull form, with different values of the shape parameter. For $shape = 1$, we get an exponential distribution:\n\n\nlibrary(eha)\n\n\n\n\n## \n## Attaching package: 'eha'\n\n\n\n\n## The following objects are masked from 'package:VGAM':\n## \n##     dgompertz, dmakeham, pgompertz, pmakeham, qgompertz, qmakeham,\n##     rgompertz, rmakeham\n\n\n\n\ny \n- with(veteran, Surv(time, status))\n\nmodel1 \n- weibreg(y ~ karno + diagtime + age + prior + celltype + trt, \n                  data = veteran, shape = 1)\nsummary(model1)\n\n\n\n\n## Call:\n## weibreg(formula = y ~ karno + diagtime + age + prior + celltype + \n##     trt, data = veteran, shape = 1)\n## \n## Covariate           Mean       Coef Exp(Coef)  se(Coef)    Wald p\n## karno              68.419    -0.031     0.970     0.005     0.000 \n## diagtime            8.139     0.000     1.000     0.009     0.974 \n## age                57.379    -0.006     0.994     0.009     0.505 \n## prior \n##                0    0.653     0         1           (reference)\n##               10    0.347     0.049     1.051     0.227     0.827 \n## celltype \n##            large    0.269     0         1           (reference)\n##         squamous    0.421    -0.377     0.686     0.273     0.166 \n##        smallcell    0.206     0.443     1.557     0.261     0.090 \n##            adeno    0.104     0.736     2.087     0.294     0.012 \n## trt \n##                1    0.477     0         1           (reference)\n##                2    0.523     0.220     1.246     0.199     0.269 \n## \n## log(scale)                    2.811    16.633     0.713     0.000 \n## \n##  Shape is fixed at  1 \n## \n## Events                    128 \n## Total time at risk         16663 \n## Max. log. likelihood      -716.16 \n## LR test statistic         70.1 \n## Degrees of freedom        8 \n## Overall p-value           4.64229e-12\n\n\n\n\nIf we take $shape = 0$, the shape parameter is estimated along with the regression coefficients:\n\n\nmodel2 \n- weibreg(y ~ karno + diagtime + age + prior + celltype + trt, \n                  data = veteran, shape = 0)\nsummary(model2)\n\n\n\n\n## Call:\n## weibreg(formula = y ~ karno + diagtime + age + prior + celltype + \n##     trt, data = veteran, shape = 0)\n## \n## Covariate           Mean       Coef Exp(Coef)  se(Coef)    Wald p\n## karno              68.419    -0.032     0.968     0.005     0.000 \n## diagtime            8.139     0.001     1.001     0.009     0.955 \n## age                57.379    -0.007     0.993     0.009     0.476 \n## prior \n##                0    0.653     0         1           (reference)\n##               10    0.347     0.047     1.048     0.229     0.836 \n## celltype \n##            large    0.269     0         1           (reference)\n##         squamous    0.421    -0.428     0.651     0.278     0.123 \n##        smallcell    0.206     0.462     1.587     0.262     0.078 \n##            adeno    0.104     0.792     2.208     0.300     0.008 \n## trt \n##                1    0.477     0         1           (reference)\n##                2    0.523     0.246     1.279     0.203     0.224 \n## \n## log(scale)                    2.864    17.537     0.671     0.000 \n## log(shape)                    0.075     1.077     0.066     0.261 \n## \n## Events                    128 \n## Total time at risk         16663 \n## Max. log. likelihood      -715.55 \n## LR test statistic         65.1 \n## Degrees of freedom        8 \n## Overall p-value           4.65393e-11\n\n\n\n\nFinally, we can also fit a Cox proportional hazard:\n\n\nmodel3 \n- coxph(y ~ karno + diagtime + age + prior + celltype + trt, \n                data = veteran)\nsummary(model3)\n\n\n\n\n## Call:\n## coxph(formula = y ~ karno + diagtime + age + prior + celltype + \n##     trt, data = veteran)\n## \n##   n= 137, number of events= 128 \n## \n##                         coef  exp(coef)   se(coef)      z Pr(\n|z|)    \n## karno             -3.282e-02  9.677e-01  5.508e-03 -5.958 2.55e-09 ***\n## diagtime           8.132e-05  1.000e+00  9.136e-03  0.009  0.99290    \n## age               -8.706e-03  9.913e-01  9.300e-03 -0.936  0.34920    \n## prior10            7.159e-02  1.074e+00  2.323e-01  0.308  0.75794    \n## celltypesquamous  -4.013e-01  6.695e-01  2.827e-01 -1.420  0.15574    \n## celltypesmallcell  4.603e-01  1.584e+00  2.662e-01  1.729  0.08383 .  \n## celltypeadeno      7.948e-01  2.214e+00  3.029e-01  2.624  0.00869 ** \n## trt2               2.946e-01  1.343e+00  2.075e-01  1.419  0.15577    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                   exp(coef) exp(-coef) lower .95 upper .95\n## karno                0.9677     1.0334    0.9573    0.9782\n## diagtime             1.0001     0.9999    0.9823    1.0182\n## age                  0.9913     1.0087    0.9734    1.0096\n## prior10              1.0742     0.9309    0.6813    1.6937\n## celltypesquamous     0.6695     1.4938    0.3847    1.1651\n## celltypesmallcell    1.5845     0.6311    0.9403    2.6699\n## celltypeadeno        2.2139     0.4517    1.2228    4.0084\n## trt2                 1.3426     0.7448    0.8939    2.0166\n## \n## Concordance= 0.736  (se = 0.03 )\n## Rsquare= 0.364   (max possible= 0.999 )\n## Likelihood ratio test= 62.1  on 8 df,   p=1.799e-10\n## Wald test            = 62.37  on 8 df,   p=1.596e-10\n## Score (logrank) test = 66.74  on 8 df,   p=2.186e-11\n\n\n\n\nAs we can see, all three models are significant, and they give similar information: \nkarno\n and \ncelltype\n are significant predictors, both treatment is not.\n\n\nThe method available in this package makes use of \ncase-base sampling\n. That is, person-moments are randomly sampled across the entire follow-up time, with some moments corresponding to cases and others to controls. By sampling person-moments instead of individuals, we can then use logistic regression to fit smooth-in-time parametric hazard functions. See the previous section for more details.\n\n\nFirst, we will look at the follow-up time by using population-time plots:\n\n\nnobs \n- nrow(y)\nftime \n- veteran$time\nord \n- order(ftime, decreasing=TRUE)\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\nsegments(rep(0.0, nobs), 1:nobs, ftime[ord], 1:nobs, col='gray25')\ncases \n- veteran$status == 1\npoints((ftime[ord])[cases[ord]], (1:nobs)[cases[ord]], pch=20, col='red', cex=0.5)\n\n\n\n\n\n\n\nPopulation-time plots are a useful way of visualizing the total follow-up experience, where individuals appear on the y-axis, and follow-up time on the x-axis; each individual's follow-up time is represented by a gray line segment. For convenience, we have ordered the patients according to their time-to-event, and each event is represented by a red dot. The censored observations (of which there is only a few) correspond to the grey lines which do not end with a red dot.\n\n\nNext, we use case-base sampling to fit a parametric hazard function via logistic regression. First, we will include time as a linear term; as noted above, this corresponds to an Gompertz hazard.\n\n\nlibrary(casebase)\nmodel4 \n- fitSmoothHazard(status ~ time + karno + diagtime + age + prior +\n             celltype + trt, data = veteran, ratio=100, type = \nuniform\n)\nsummary(model4)\n\n\n\n\n## \n## Call:\n## glm(formula = formula, family = binomial(link = link), data = sampleData)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.4334  -0.1494  -0.1206  -0.0994   3.4111  \n## \n## Coefficients:\n##                     Estimate Std. Error z value Pr(\n|z|)    \n## (Intercept)       -2.7865611  0.7262061  -3.837 0.000124 ***\n## time               0.0003885  0.0006458   0.602 0.547478    \n## karno             -0.0320120  0.0052834  -6.059 1.37e-09 ***\n## diagtime          -0.0007069  0.0093722  -0.075 0.939876    \n## age               -0.0050225  0.0092409  -0.544 0.586779    \n## prior10            0.0358793  0.2311075   0.155 0.876625    \n## celltypesquamous  -0.4118927  0.2835803  -1.452 0.146370    \n## celltypesmallcell  0.4395790  0.2624502   1.675 0.093953 .  \n## celltypeadeno      0.7470542  0.3007795   2.484 0.013002 *  \n## trt2               0.1688823  0.2010431   0.840 0.400891    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1436.2  on 12927  degrees of freedom\n## Residual deviance: 1364.6  on 12918  degrees of freedom\n## AIC: 1384.6\n## \n## Number of Fisher Scoring iterations: 8\n\n\n\n\nSince the output object from \nfitSmoothHazard\n inherits from the \nglm\n class, we see a familiar result when using the function \nsummary\n.\n\n\nThe main purpose of fitting smooth hazard functions is that it is then relatively easy to compute absolute risks. For example, we can use the function \nabsoluteRisk\n to compute the mean absolute risk at 90 days, which can then be compared to the empirical measure.\n\n\nabsoluteRisk(object = model4, time = 90)\n\n\n\n\n## [1] 0.5778068\n\n\n\n\nmean(ftime \n= 90)\n\n\n\n\n## [1] 0.5547445\n\n\n\n\nWe can also fit a Weibull hazard by using a logarithmic term for time:\n\n\nmodel5 \n- fitSmoothHazard(status ~ log(time) + karno + diagtime + age + prior +\n             celltype + trt, data = veteran, ratio=100, type = \nuniform\n)\nsummary(model5)\n\n\n\n\n## \n## Call:\n## glm(formula = formula, family = binomial(link = link), data = sampleData)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.4267  -0.1497  -0.1190  -0.0974   3.3902  \n## \n## Coefficients:\n##                    Estimate Std. Error z value Pr(\n|z|)    \n## (Intercept)       -3.132306   0.749307  -4.180 2.91e-05 ***\n## log(time)          0.083588   0.072277   1.156   0.2475    \n## karno             -0.031532   0.005447  -5.789 7.10e-09 ***\n## diagtime           0.004232   0.009319   0.454   0.6497    \n## age               -0.006194   0.009266  -0.669   0.5038    \n## prior10           -0.036590   0.229620  -0.159   0.8734    \n## celltypesquamous  -0.421632   0.279068  -1.511   0.1308    \n## celltypesmallcell  0.495420   0.263323   1.881   0.0599 .  \n## celltypeadeno      0.740552   0.301669   2.455   0.0141 *  \n## trt2               0.261555   0.203048   1.288   0.1977    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1436.2  on 12927  degrees of freedom\n## Residual deviance: 1366.9  on 12918  degrees of freedom\n## AIC: 1386.9\n## \n## Number of Fisher Scoring iterations: 8\n\n\n\n\nWith case-base sampling, it is straightforward to fit a semi-parametric hazard function using splines, which can then be used to estimate the mean absolute risk.\n\n\n# Fit a spline for time\nlibrary(splines)\nmodel6 \n- fitSmoothHazard(status ~ bs(time) + karno + diagtime + age + prior +\n             celltype + trt, data = veteran, ratio=100, type = \nuniform\n)\nsummary(model6)\n\n\n\n\n## \n## Call:\n## glm(formula = formula, family = binomial(link = link), data = sampleData)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.4523  -0.1540  -0.1194  -0.0962   3.5368  \n## \n## Coefficients:\n##                    Estimate Std. Error z value Pr(\n|z|)    \n## (Intercept)       -2.923789   0.718830  -4.067 4.75e-05 ***\n## bs(time)1          1.654492   1.022068   1.619  0.10550    \n## bs(time)2         -2.786087   1.780166  -1.565  0.11757    \n## bs(time)3          1.782795   1.009755   1.766  0.07747 .  \n## karno             -0.032825   0.005467  -6.005 1.92e-09 ***\n## diagtime          -0.001902   0.009045  -0.210  0.83346    \n## age               -0.006261   0.009449  -0.663  0.50760    \n## prior10            0.063173   0.234174   0.270  0.78734    \n## celltypesquamous  -0.306083   0.281703  -1.087  0.27724    \n## celltypesmallcell  0.479477   0.268042   1.789  0.07364 .  \n## celltypeadeno      0.874292   0.301055   2.904  0.00368 ** \n## trt2               0.204717   0.204870   0.999  0.31767    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1436.2  on 12927  degrees of freedom\n## Residual deviance: 1365.3  on 12916  degrees of freedom\n## AIC: 1389.3\n## \n## Number of Fisher Scoring iterations: 8\n\n\n\n\nabsoluteRisk(object = model6, time = 90)\n\n\n\n\n## [1] 0.5733611\n\n\n\n\nAs we can see from the summary, there is little evidence that splines actually improve the fit. Moreover, we can see that estimated individual absolute risks are essentially the same when using either a linear term or splines:\n\n\nlinearRisk \n- absoluteRisk(object = model4, time = 90, newdata = veteran)\nsplineRisk \n- absoluteRisk(object = model6, time = 90, newdata = veteran)\n\nplot(linearRisk, splineRisk,\n     xlab=\nLinear\n, ylab = \nSplines\n, pch=19)\nabline(a=0, b=1, lty=2, lwd=2, col='red')\n\n\n\n\n\n\n\nThese last three models give similar information as the first three, i.e. the main predictors for the hazard are \nkarno\n and \ncelltype\n, with treatment being non-significant. Moreover, by explicitely including the time variable in the formula, we see that it is not significant; this is evidence that the true hazard is exponential.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession information\n\n\n## R version 3.2.3 (2015-12-10)\n## Platform: x86_64-pc-linux-gnu (64-bit)\n## Running under: Ubuntu 14.04.4 LTS\n## \n## locale:\n##  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C              \n##  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    \n##  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8   \n##  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n## [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n## \n## attached base packages:\n## [1] splines   stats4    stats     graphics  grDevices utils     datasets \n## [8] methods   base     \n## \n## other attached packages:\n## [1] eha_2.4-3         survival_2.38-3   VGAM_1.0-0        casebase_0.0.9000\n## \n## loaded via a namespace (and not attached):\n##  [1] digest_0.6.9    formatR_1.2.1   magrittr_1.5    evaluate_0.8   \n##  [5] stringi_1.0-1   rmarkdown_0.9.2 devtools_1.10.0 tools_3.2.3    \n##  [9] stringr_1.0.0   yaml_2.1.13     memoise_1.0.0   htmltools_0.3  \n## [13] knitr_1.12.3", 
            "title": "Smooth Hazard"
        }, 
        {
            "location": "/smoothhazard/#methodological-details", 
            "text": "Case-base sampling was proposed by Hanley   Miettinen [-@hanley2009fitting] as a way to fit smooth-in-time parametric hazard functions via logistic regression. The main idea, which was first proposed by Mantel [-@mantel1973synthetic] and then later developped by Efron [-@efron1977efficiency], is to sample person-moments, i.e. discrete time points along an subject's follow-up time, in order to construct a base series against which the case series can be compared.   This approach allows the explicit inclusion of the time variable into the model, which enables the user to fit a wide class of parametric hazard functions. For example, including time linearly recovers the Gompertz hazard, whereas including time  logarithmically  recovers the Weibull hazard; not including time at all corresponds to the exponential hazard.  The theoretical properties of this approach have been studied in Saarela   Arjas [-@saarela2015non] and Saarela [-@saarela2015case].", 
            "title": "Methodological details"
        }, 
        {
            "location": "/smoothhazard/#first-example-veteran-dataset", 
            "text": "The first example we discuss uses the well-known  veteran  dataset, which is part of the  survival  package. As we can see below, there is almost no censoring, and therefore we can get a good visual representation of the survival function:  library(survival)  ## \n## Attaching package: 'survival'  ## The following object is masked _by_ '.GlobalEnv':\n## \n##     veteran  data(veteran)\ntable(veteran$status)  ## \n##   0   1 \n##   9 128  evtimes  - veteran$time[veteran$status == 1]\nhist(evtimes, nclass=30, main='', xlab='Survival time (days)', col='gray90', probability=TRUE)\ntgrid  - seq(0, 1000, by=10)\nlines(tgrid, dexp(tgrid, rate=1.0/mean(evtimes)), \n      lwd=2, lty=2, col='red')   As we can see, the empirical survival function ressembles an exponential distribution.", 
            "title": "First example: Veteran dataset"
        }, 
        {
            "location": "/smoothhazard/#estimating-hazard-function-parametrically", 
            "text": "We will first try to estimate the hazard function parametrically using some well-known regression routines. But first, we will reformat the data slightly.  veteran$prior  - factor(veteran$prior, levels = c(0, 10))\nveteran$celltype  - factor(veteran$celltype, \n                           levels = c('large', 'squamous', 'smallcell', 'adeno'))\nveteran$trt  - factor(veteran$trt, levels = c(1, 2))  Using the  eha  package, we can fit a Weibull form, with different values of the shape parameter. For $shape = 1$, we get an exponential distribution:  library(eha)  ## \n## Attaching package: 'eha'  ## The following objects are masked from 'package:VGAM':\n## \n##     dgompertz, dmakeham, pgompertz, pmakeham, qgompertz, qmakeham,\n##     rgompertz, rmakeham  y  - with(veteran, Surv(time, status))\n\nmodel1  - weibreg(y ~ karno + diagtime + age + prior + celltype + trt, \n                  data = veteran, shape = 1)\nsummary(model1)  ## Call:\n## weibreg(formula = y ~ karno + diagtime + age + prior + celltype + \n##     trt, data = veteran, shape = 1)\n## \n## Covariate           Mean       Coef Exp(Coef)  se(Coef)    Wald p\n## karno              68.419    -0.031     0.970     0.005     0.000 \n## diagtime            8.139     0.000     1.000     0.009     0.974 \n## age                57.379    -0.006     0.994     0.009     0.505 \n## prior \n##                0    0.653     0         1           (reference)\n##               10    0.347     0.049     1.051     0.227     0.827 \n## celltype \n##            large    0.269     0         1           (reference)\n##         squamous    0.421    -0.377     0.686     0.273     0.166 \n##        smallcell    0.206     0.443     1.557     0.261     0.090 \n##            adeno    0.104     0.736     2.087     0.294     0.012 \n## trt \n##                1    0.477     0         1           (reference)\n##                2    0.523     0.220     1.246     0.199     0.269 \n## \n## log(scale)                    2.811    16.633     0.713     0.000 \n## \n##  Shape is fixed at  1 \n## \n## Events                    128 \n## Total time at risk         16663 \n## Max. log. likelihood      -716.16 \n## LR test statistic         70.1 \n## Degrees of freedom        8 \n## Overall p-value           4.64229e-12  If we take $shape = 0$, the shape parameter is estimated along with the regression coefficients:  model2  - weibreg(y ~ karno + diagtime + age + prior + celltype + trt, \n                  data = veteran, shape = 0)\nsummary(model2)  ## Call:\n## weibreg(formula = y ~ karno + diagtime + age + prior + celltype + \n##     trt, data = veteran, shape = 0)\n## \n## Covariate           Mean       Coef Exp(Coef)  se(Coef)    Wald p\n## karno              68.419    -0.032     0.968     0.005     0.000 \n## diagtime            8.139     0.001     1.001     0.009     0.955 \n## age                57.379    -0.007     0.993     0.009     0.476 \n## prior \n##                0    0.653     0         1           (reference)\n##               10    0.347     0.047     1.048     0.229     0.836 \n## celltype \n##            large    0.269     0         1           (reference)\n##         squamous    0.421    -0.428     0.651     0.278     0.123 \n##        smallcell    0.206     0.462     1.587     0.262     0.078 \n##            adeno    0.104     0.792     2.208     0.300     0.008 \n## trt \n##                1    0.477     0         1           (reference)\n##                2    0.523     0.246     1.279     0.203     0.224 \n## \n## log(scale)                    2.864    17.537     0.671     0.000 \n## log(shape)                    0.075     1.077     0.066     0.261 \n## \n## Events                    128 \n## Total time at risk         16663 \n## Max. log. likelihood      -715.55 \n## LR test statistic         65.1 \n## Degrees of freedom        8 \n## Overall p-value           4.65393e-11  Finally, we can also fit a Cox proportional hazard:  model3  - coxph(y ~ karno + diagtime + age + prior + celltype + trt, \n                data = veteran)\nsummary(model3)  ## Call:\n## coxph(formula = y ~ karno + diagtime + age + prior + celltype + \n##     trt, data = veteran)\n## \n##   n= 137, number of events= 128 \n## \n##                         coef  exp(coef)   se(coef)      z Pr( |z|)    \n## karno             -3.282e-02  9.677e-01  5.508e-03 -5.958 2.55e-09 ***\n## diagtime           8.132e-05  1.000e+00  9.136e-03  0.009  0.99290    \n## age               -8.706e-03  9.913e-01  9.300e-03 -0.936  0.34920    \n## prior10            7.159e-02  1.074e+00  2.323e-01  0.308  0.75794    \n## celltypesquamous  -4.013e-01  6.695e-01  2.827e-01 -1.420  0.15574    \n## celltypesmallcell  4.603e-01  1.584e+00  2.662e-01  1.729  0.08383 .  \n## celltypeadeno      7.948e-01  2.214e+00  3.029e-01  2.624  0.00869 ** \n## trt2               2.946e-01  1.343e+00  2.075e-01  1.419  0.15577    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                   exp(coef) exp(-coef) lower .95 upper .95\n## karno                0.9677     1.0334    0.9573    0.9782\n## diagtime             1.0001     0.9999    0.9823    1.0182\n## age                  0.9913     1.0087    0.9734    1.0096\n## prior10              1.0742     0.9309    0.6813    1.6937\n## celltypesquamous     0.6695     1.4938    0.3847    1.1651\n## celltypesmallcell    1.5845     0.6311    0.9403    2.6699\n## celltypeadeno        2.2139     0.4517    1.2228    4.0084\n## trt2                 1.3426     0.7448    0.8939    2.0166\n## \n## Concordance= 0.736  (se = 0.03 )\n## Rsquare= 0.364   (max possible= 0.999 )\n## Likelihood ratio test= 62.1  on 8 df,   p=1.799e-10\n## Wald test            = 62.37  on 8 df,   p=1.596e-10\n## Score (logrank) test = 66.74  on 8 df,   p=2.186e-11  As we can see, all three models are significant, and they give similar information:  karno  and  celltype  are significant predictors, both treatment is not.  The method available in this package makes use of  case-base sampling . That is, person-moments are randomly sampled across the entire follow-up time, with some moments corresponding to cases and others to controls. By sampling person-moments instead of individuals, we can then use logistic regression to fit smooth-in-time parametric hazard functions. See the previous section for more details.  First, we will look at the follow-up time by using population-time plots:  nobs  - nrow(y)\nftime  - veteran$time\nord  - order(ftime, decreasing=TRUE)\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\nsegments(rep(0.0, nobs), 1:nobs, ftime[ord], 1:nobs, col='gray25')\ncases  - veteran$status == 1\npoints((ftime[ord])[cases[ord]], (1:nobs)[cases[ord]], pch=20, col='red', cex=0.5)   Population-time plots are a useful way of visualizing the total follow-up experience, where individuals appear on the y-axis, and follow-up time on the x-axis; each individual's follow-up time is represented by a gray line segment. For convenience, we have ordered the patients according to their time-to-event, and each event is represented by a red dot. The censored observations (of which there is only a few) correspond to the grey lines which do not end with a red dot.  Next, we use case-base sampling to fit a parametric hazard function via logistic regression. First, we will include time as a linear term; as noted above, this corresponds to an Gompertz hazard.  library(casebase)\nmodel4  - fitSmoothHazard(status ~ time + karno + diagtime + age + prior +\n             celltype + trt, data = veteran, ratio=100, type =  uniform )\nsummary(model4)  ## \n## Call:\n## glm(formula = formula, family = binomial(link = link), data = sampleData)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.4334  -0.1494  -0.1206  -0.0994   3.4111  \n## \n## Coefficients:\n##                     Estimate Std. Error z value Pr( |z|)    \n## (Intercept)       -2.7865611  0.7262061  -3.837 0.000124 ***\n## time               0.0003885  0.0006458   0.602 0.547478    \n## karno             -0.0320120  0.0052834  -6.059 1.37e-09 ***\n## diagtime          -0.0007069  0.0093722  -0.075 0.939876    \n## age               -0.0050225  0.0092409  -0.544 0.586779    \n## prior10            0.0358793  0.2311075   0.155 0.876625    \n## celltypesquamous  -0.4118927  0.2835803  -1.452 0.146370    \n## celltypesmallcell  0.4395790  0.2624502   1.675 0.093953 .  \n## celltypeadeno      0.7470542  0.3007795   2.484 0.013002 *  \n## trt2               0.1688823  0.2010431   0.840 0.400891    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1436.2  on 12927  degrees of freedom\n## Residual deviance: 1364.6  on 12918  degrees of freedom\n## AIC: 1384.6\n## \n## Number of Fisher Scoring iterations: 8  Since the output object from  fitSmoothHazard  inherits from the  glm  class, we see a familiar result when using the function  summary .  The main purpose of fitting smooth hazard functions is that it is then relatively easy to compute absolute risks. For example, we can use the function  absoluteRisk  to compute the mean absolute risk at 90 days, which can then be compared to the empirical measure.  absoluteRisk(object = model4, time = 90)  ## [1] 0.5778068  mean(ftime  = 90)  ## [1] 0.5547445  We can also fit a Weibull hazard by using a logarithmic term for time:  model5  - fitSmoothHazard(status ~ log(time) + karno + diagtime + age + prior +\n             celltype + trt, data = veteran, ratio=100, type =  uniform )\nsummary(model5)  ## \n## Call:\n## glm(formula = formula, family = binomial(link = link), data = sampleData)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.4267  -0.1497  -0.1190  -0.0974   3.3902  \n## \n## Coefficients:\n##                    Estimate Std. Error z value Pr( |z|)    \n## (Intercept)       -3.132306   0.749307  -4.180 2.91e-05 ***\n## log(time)          0.083588   0.072277   1.156   0.2475    \n## karno             -0.031532   0.005447  -5.789 7.10e-09 ***\n## diagtime           0.004232   0.009319   0.454   0.6497    \n## age               -0.006194   0.009266  -0.669   0.5038    \n## prior10           -0.036590   0.229620  -0.159   0.8734    \n## celltypesquamous  -0.421632   0.279068  -1.511   0.1308    \n## celltypesmallcell  0.495420   0.263323   1.881   0.0599 .  \n## celltypeadeno      0.740552   0.301669   2.455   0.0141 *  \n## trt2               0.261555   0.203048   1.288   0.1977    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1436.2  on 12927  degrees of freedom\n## Residual deviance: 1366.9  on 12918  degrees of freedom\n## AIC: 1386.9\n## \n## Number of Fisher Scoring iterations: 8  With case-base sampling, it is straightforward to fit a semi-parametric hazard function using splines, which can then be used to estimate the mean absolute risk.  # Fit a spline for time\nlibrary(splines)\nmodel6  - fitSmoothHazard(status ~ bs(time) + karno + diagtime + age + prior +\n             celltype + trt, data = veteran, ratio=100, type =  uniform )\nsummary(model6)  ## \n## Call:\n## glm(formula = formula, family = binomial(link = link), data = sampleData)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.4523  -0.1540  -0.1194  -0.0962   3.5368  \n## \n## Coefficients:\n##                    Estimate Std. Error z value Pr( |z|)    \n## (Intercept)       -2.923789   0.718830  -4.067 4.75e-05 ***\n## bs(time)1          1.654492   1.022068   1.619  0.10550    \n## bs(time)2         -2.786087   1.780166  -1.565  0.11757    \n## bs(time)3          1.782795   1.009755   1.766  0.07747 .  \n## karno             -0.032825   0.005467  -6.005 1.92e-09 ***\n## diagtime          -0.001902   0.009045  -0.210  0.83346    \n## age               -0.006261   0.009449  -0.663  0.50760    \n## prior10            0.063173   0.234174   0.270  0.78734    \n## celltypesquamous  -0.306083   0.281703  -1.087  0.27724    \n## celltypesmallcell  0.479477   0.268042   1.789  0.07364 .  \n## celltypeadeno      0.874292   0.301055   2.904  0.00368 ** \n## trt2               0.204717   0.204870   0.999  0.31767    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1436.2  on 12927  degrees of freedom\n## Residual deviance: 1365.3  on 12916  degrees of freedom\n## AIC: 1389.3\n## \n## Number of Fisher Scoring iterations: 8  absoluteRisk(object = model6, time = 90)  ## [1] 0.5733611  As we can see from the summary, there is little evidence that splines actually improve the fit. Moreover, we can see that estimated individual absolute risks are essentially the same when using either a linear term or splines:  linearRisk  - absoluteRisk(object = model4, time = 90, newdata = veteran)\nsplineRisk  - absoluteRisk(object = model6, time = 90, newdata = veteran)\n\nplot(linearRisk, splineRisk,\n     xlab= Linear , ylab =  Splines , pch=19)\nabline(a=0, b=1, lty=2, lwd=2, col='red')   These last three models give similar information as the first three, i.e. the main predictors for the hazard are  karno  and  celltype , with treatment being non-significant. Moreover, by explicitely including the time variable in the formula, we see that it is not significant; this is evidence that the true hazard is exponential.", 
            "title": "Estimating Hazard Function Parametrically"
        }, 
        {
            "location": "/smoothhazard/#session-information", 
            "text": "## R version 3.2.3 (2015-12-10)\n## Platform: x86_64-pc-linux-gnu (64-bit)\n## Running under: Ubuntu 14.04.4 LTS\n## \n## locale:\n##  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C              \n##  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    \n##  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8   \n##  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n## [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n## \n## attached base packages:\n## [1] splines   stats4    stats     graphics  grDevices utils     datasets \n## [8] methods   base     \n## \n## other attached packages:\n## [1] eha_2.4-3         survival_2.38-3   VGAM_1.0-0        casebase_0.0.9000\n## \n## loaded via a namespace (and not attached):\n##  [1] digest_0.6.9    formatR_1.2.1   magrittr_1.5    evaluate_0.8   \n##  [5] stringi_1.0-1   rmarkdown_0.9.2 devtools_1.10.0 tools_3.2.3    \n##  [9] stringr_1.0.0   yaml_2.1.13     memoise_1.0.0   htmltools_0.3  \n## [13] knitr_1.12.3", 
            "title": "Session information"
        }, 
        {
            "location": "/competingRisk/", 
            "text": "Competing risk analysis using case-base sampling\n\n\nMaxime Turgeon\n\n\nr Sys.Date()\n  \n\n\nData\n\n\nWe will use the same data that was used in Scrucca \net al\n [-@scrucca2010regression]. The data is available on the main author's \nwebsite\n.\n\n\nDT \n- read.csv(system.file(\nextdata\n, \nbmtcrr.csv\n, package = \ncasebase\n))\nhead(DT)\n\n\n\n\n##   Sex   D   Phase Age Status Source  ftime\n## 1   M ALL Relapse  48      2  BM+PB   0.67\n## 2   F AML     CR2  23      1  BM+PB   9.50\n## 3   M ALL     CR3   7      0  BM+PB 131.77\n## 4   F ALL     CR2  26      2  BM+PB  24.03\n## 5   F ALL     CR2  36      2  BM+PB   1.47\n## 6   M ALL Relapse  17      2  BM+PB   2.23\n\n\n\n\nWe will perform a competing risk analysis on data from 177 patients who received a stem cell transplant for acute leukemia. The event of interest in relapse, but other competing causes (e.g. transplant-related death) need to be taken into account. We also want to take into account the effect of several covariates such as Sex, Disease (lymphoblastic or myeloblastic leukemia, abbreviated as ALL and AML, respectively), Phase at transplant (Relapse, CR1, CR2, CR3), Source of stem cells (bone marrow and peripheral blood, coded as BM+PB, or peripheral blood, coded as PB), and Age. Below, we reproduce their Table 1:\n\n\n\n\n\n\n\n\nVariable\n\n\nDescription\n\n\nStatistical summary\n\n\n\n\n\n\n\n\n\n\nSex\n\n\nSex\n\n\nM=Male (100) \n F=Female (77)\n\n\n\n\n\n\nD\n\n\nDisease\n\n\nALL (73) \n AML (104)\n\n\n\n\n\n\nPhase\n\n\nPhase\n\n\nCR1 (47) \n CR2 (45) \n CR3 (12) \n Relapse (73)\n\n\n\n\n\n\nSource\n\n\nType of transplant\n\n\nBM+PB (21) \n PB (156)\n\n\n\n\n\n\nAge\n\n\nAge of patient (years)\n\n\n4\u201362 \n 30.47 (13.04)\n\n\n\n\n\n\nFtime\n\n\nFailure time (months)\n\n\n0.13\u2013131.77 \n 20.28 (30.78)\n\n\n\n\n\n\nStatus\n\n\nStatus indicator\n\n\n0=censored (46) \n 1=relapse (56) \n 2=competing event (75)\n\n\n\n\n\n\n\n\nThe statistical summary is generated differently for continuous and categorical variables: \n\n\n\n\n\n\nFor continuous variables, we are given the range, followed by the mean and standard deviation.\n\n\n\n\n\n\nFor categorical variables, we are given the counts for each category.\n\n\n\n\n\n\nNote that failure time can also correspond to censoring.\n\n\nPopulation-time plots\n\n\nIn order to try and visualize the incidence density of relapse, we can look at a population-time plot: on the X-axis we have time, and on the Y-axis we have the size of the risk set at a particular time point. Failure times associated to the event of interest can then be highlighted on the plot using red dots.\n\n\nnobs \n- nrow(DT)\nftime \n- DT$ftime\nord \n- order(ftime, decreasing=FALSE)\n\n# We split the person-moments in four categories:\n# 1) at-risk\n# 2) main event\n# 3) competing event\n# 4) censored\nyCoords \n- cbind(cumsum(DT[ord, \nStatus\n] == 2), \n                 cumsum(DT[ord, \nStatus\n] == 1),\n                 cumsum(DT[ord, \nStatus\n] == 0))\nyCoords \n- cbind(yCoords, nobs - rowSums(yCoords))\n\n# Plot only at-risk\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\npolygon(c(0, 0, ftime[ord], max(ftime), 0),\n        c(0, nobs, yCoords[,4], 0, 0), col = \ngrey90\n)\ncases \n- DT[, \nStatus\n] == 1\n\n# randomly move the cases vertically\nmoved_cases \n- yCoords[cases[ord], 4] * runif(sum(cases))\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col=\nred\n, cex=1)\n\n\n\n\n \n\n\nWe can right away draw a few conclusions from this plot: first of all, we get a sense of how quickly the size of the risk set changes over time. We also see that the incidence density is non-constant: most relapses occur before 15 months. Finally, we also see that the risk set keeps shrinking after the last event has occured; this could be due to either censoring or the competing event.\n\n\nTo get an idea of whether only relapse is responsible for the shrinking of the risk set in the first few months of follow-up, we can also keep track of how many events have occured at each time point:\n\n\n# Plot at-risk and events\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\npolygon(c(0,ftime[ord], max(ftime), 0), c(0, yCoords[,2], 0, 0), col = \nfirebrick3\n)\npolygon(c(0, ftime[ord], ftime[rev(ord)], 0, 0),\n        c(0, yCoords[,2], rev(yCoords[,2] + yCoords[,4]), nobs, 0), col = \ngrey90\n)\n\n# randomly move the cases vertically\nmoved_cases \n- yCoords[cases[ord], 2] + yCoords[cases[ord], 4] * runif(sum(cases))\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col=\nred\n, cex=1)\nlegend(\ntopright\n, legend=c(\nRelapse\n, \nAt-risk\n), \n       col=c(\nfirebrick3\n, \ngrey90\n),\n       pch=15)\n\n\n\n\n \n\n\nTherefore, there is also censoring and loss due to competing events happening in the first few months. However, with this plot, we can't differentiate bwetween the two contributions. For this reason we can also keep track of the number of competing events at each time point:\n\n\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\npolygon(c(0, max(ftime), max(ftime), 0),\n        c(0, 0, nobs, nobs), col = \nwhite\n)\n# Event of interest\npolygon(c(0,ftime[ord], max(ftime), 0), c(0, yCoords[,2], 0, 0), col = \nfirebrick3\n)\n# Risk set\npolygon(c(0, ftime[ord], ftime[rev(ord)], 0, 0),\n        c(0, yCoords[,2], rev(yCoords[,2] + yCoords[,4]), nobs, 0), col = \ngrey90\n)\n# Competing event\npolygon(c(0, ftime[ord], max(ftime), 0), c(nobs, nobs - yCoords[,1], nobs, nobs), col = \ndodgerblue2\n)\n\n# randomly move the cases vertically\nmoved_cases \n- yCoords[cases[ord], 2] + yCoords[cases[ord], 4] * runif(sum(cases))\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col=\nred\n, cex=1)\nlegend(\ntopright\n, legend=c(\nRelapse\n, \nCompeting event\n, \nAt-risk\n), \n       col=c(\nfirebrick3\n, \ndodgerblue2\n, \ngrey90\n),\n       pch=15)\n\n\n\n\n \n\n\nFrom this last plot, we can see that there is no censoring during the first 10 months. Moreover, we see that the last competing event occurs around 20 months. Putting all this information together, we have evidence of two types of patients: very sick patients who either relapse or have a competing event early on, and healthier patients who are eventually lost to follow-up.\n\n\nAnalysis\n\n\nWe now turn to the analysis of this dataset. The population-time plots above give evidence of non-constant hazard; therefore, we will explicitely include time in the model. Note that we also include all other variables as possible confounders. First, we include time as a linear term:\n\n\nlibrary(casebase)\nmodel1 \n- fitSmoothHazard(Status ~ ftime + Sex + D + Phase + Source + Age, \n                          data = DT, ratio=1000, type = \nuniform\n, time=\nftime\n)\nsummary(model1)\n\n\n\n\n## \n## Call:\n## vglm(formula = formula, family = multinomial(refLevel = 1), data = sampleData)\n## \n## Pearson residuals:\n##                         Min       1Q   Median        3Q    Max\n## log(mu[,2]/mu[,1]) -0.07345 -0.02205 -0.01239 -0.004704 144.73\n## log(mu[,3]/mu[,1]) -0.10895 -0.02841 -0.01179 -0.002704  63.41\n## \n## Coefficients:\n##                 Estimate Std. Error z value Pr(\n|z|)    \n## (Intercept):1  -3.474588   0.680663  -5.105 3.31e-07 ***\n## (Intercept):2  -2.549614   0.459171  -5.553 2.81e-08 ***\n## ftime:1        -0.069401   0.014631  -4.744 2.10e-06 ***\n## ftime:2        -0.103346   0.018076  -5.717 1.08e-08 ***\n## SexM:1         -0.293579   0.281057  -1.045  0.29623    \n## SexM:2         -0.408156   0.234223  -1.743  0.08140 .  \n## DAML:1         -0.629272   0.298733  -2.106  0.03516 *  \n## DAML:2         -0.136885   0.274495  -0.499  0.61800    \n## PhaseCR2:1      0.191556   0.465535   0.411  0.68072    \n## PhaseCR2:2      0.290034   0.329955   0.879  0.37940    \n## PhaseCR3:1      0.509231   0.690816   0.737  0.46104    \n## PhaseCR3:2      0.248652   0.523925   0.475  0.63508    \n## PhaseRelapse:1  1.452848   0.390601   3.720  0.00020 ***\n## PhaseRelapse:2  0.779157   0.306387   2.543  0.01099 *  \n## SourcePB:1      0.454649   0.568322   0.800  0.42372    \n## SourcePB:2     -1.079430   0.353163  -3.056  0.00224 ** \n## Age:1          -0.006372   0.011866  -0.537  0.59125    \n## Age:2           0.028030   0.009902   2.831  0.00464 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Number of linear predictors:  2 \n## \n## Names of linear predictors: log(mu[,2]/mu[,1]), log(mu[,3]/mu[,1])\n## \n## Dispersion Parameter for multinomial family:   1\n## \n## Residual deviance: 2009.985 on 262244 degrees of freedom\n## \n## Log-likelihood: -1004.992 on 262244 degrees of freedom\n## \n## Number of iterations: 13 \n## \n## Reference group is level  1  of the response\n\n\n\n\nBecause of the results in Turgeon \net al\n [-@turgeonCompRisk], the standard errors we obtain from the multinomial logit fit are asymptotically correct, and therefore can be used to construct asymptotic confidence intervals. \n\n\nFrom this summary, we see that time is indeed significant, as is Phase (only relapse vs. CR1). Interestingly, we see that the type of disease is only significant for the event of interest, whereas the type of transplant and the age of the patient are only significant for the competing event.\n\n\nNext, we include the logarithm of time in the model (which leads to a Weibull hazard):\n\n\nmodel2 \n- fitSmoothHazard(Status ~ log(ftime) + Sex + D + Phase + Source + Age, \n                          data = DT, ratio=1000, type = \nuniform\n, time=\nftime\n)\nsummary(model2)\n\n\n\n\n## \n## Call:\n## vglm(formula = formula, family = multinomial(refLevel = 1), data = sampleData)\n## \n## Pearson residuals:\n##                        Min       1Q   Median       3Q   Max\n## log(mu[,2]/mu[,1]) -0.1723 -0.02169 -0.01484 -0.01120 91.45\n## log(mu[,3]/mu[,1]) -0.2699 -0.02450 -0.01754 -0.01444 69.01\n## \n## Coefficients:\n##                 Estimate Std. Error z value Pr(\n|z|)    \n## (Intercept):1  -3.931793   0.701633  -5.604 2.10e-08 ***\n## (Intercept):2  -3.043980   0.459504  -6.624 3.48e-11 ***\n## log(ftime):1   -0.326174   0.067934  -4.801 1.58e-06 ***\n## log(ftime):2   -0.405412   0.054786  -7.400 1.36e-13 ***\n## SexM:1         -0.452946   0.291820  -1.552 0.120628    \n## SexM:2         -0.515177   0.239316  -2.153 0.031342 *  \n## DAML:1         -0.682449   0.303771  -2.247 0.024666 *  \n## DAML:2         -0.149322   0.287263  -0.520 0.603197    \n## PhaseCR2:1      0.261893   0.467302   0.560 0.575181    \n## PhaseCR2:2      0.385421   0.329610   1.169 0.242273    \n## PhaseCR3:1      0.438951   0.710562   0.618 0.536738    \n## PhaseCR3:2      0.082495   0.532621   0.155 0.876912    \n## PhaseRelapse:1  1.497704   0.392762   3.813 0.000137 ***\n## PhaseRelapse:2  0.880194   0.307423   2.863 0.004195 ** \n## SourcePB:1      0.651808   0.600985   1.085 0.278114    \n## SourcePB:2     -0.971796   0.368542  -2.637 0.008368 ** \n## Age:1          -0.004476   0.011733  -0.382 0.702822    \n## Age:2           0.027958   0.009871   2.832 0.004620 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Number of linear predictors:  2 \n## \n## Names of linear predictors: log(mu[,2]/mu[,1]), log(mu[,3]/mu[,1])\n## \n## Dispersion Parameter for multinomial family:   1\n## \n## Residual deviance: 2104.931 on 262244 degrees of freedom\n## \n## Log-likelihood: -1052.465 on 262244 degrees of freedom\n## \n## Number of iterations: 11 \n## \n## Reference group is level  1  of the response\n\n\n\n\nAs we can see, the results are similar to the ones with a Gompertz hazard, although Sex is now significant for the competing event.\n\n\nFinally, using splines, we can be quite flexible about the way the hazard depends on time:\n\n\nmodel3 \n- fitSmoothHazard(Status ~ bs(ftime) + Sex + D + Phase + Source + Age, \n                          data = DT, ratio=1000, type = \nuniform\n, time=\nftime\n)\nsummary(model3)\n\n\n\n\n## \n## Call:\n## vglm(formula = formula, family = multinomial(refLevel = 1), data = sampleData)\n## \n## Pearson residuals:\n##                         Min       1Q    Median         3Q   Max\n## log(mu[,2]/mu[,1]) -0.06477 -0.02234 -0.012758 -2.412e-03 177.3\n## log(mu[,3]/mu[,1]) -0.08998 -0.03014 -0.004554 -2.306e-06 118.6\n## \n## Coefficients:\n##                  Estimate Std. Error z value Pr(\n|z|)    \n## (Intercept):1   -3.741211   0.704544  -5.310 1.10e-07 ***\n## (Intercept):2   -3.269145   0.506820  -6.450 1.12e-10 ***\n## bs(ftime)1:1     0.007116   2.263182   0.003 0.997491    \n## bs(ftime)1:2     7.001805   3.651896   1.917 0.055199 .  \n## bs(ftime)2:1   -16.189451   8.163262  -1.983 0.047344 *  \n## bs(ftime)2:2   -77.534046  25.577967  -3.031 0.002435 ** \n## bs(ftime)3:1    -2.417463  10.211989  -0.237 0.812868    \n## bs(ftime)3:2    -2.437630  22.304549  -0.109 0.912974    \n## SexM:1          -0.287843   0.282408  -1.019 0.308086    \n## SexM:2          -0.402536   0.235158  -1.712 0.086939 .  \n## DAML:1          -0.632579   0.299835  -2.110 0.034879 *  \n## DAML:2          -0.163313   0.273080  -0.598 0.549813    \n## PhaseCR2:1       0.159591   0.465919   0.343 0.731953    \n## PhaseCR2:2       0.292454   0.330122   0.886 0.375673    \n## PhaseCR3:1       0.523730   0.693387   0.755 0.450056    \n## PhaseCR3:2       0.261503   0.524775   0.498 0.618262    \n## PhaseRelapse:1   1.476824   0.394558   3.743 0.000182 ***\n## PhaseRelapse:2   0.877603   0.310625   2.825 0.004724 ** \n## SourcePB:1       0.431423   0.572585   0.753 0.451170    \n## SourcePB:2      -1.131722   0.356749  -3.172 0.001512 ** \n## Age:1           -0.004786   0.012043  -0.397 0.691044    \n## Age:2            0.030841   0.010086   3.058 0.002229 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Number of linear predictors:  2 \n## \n## Names of linear predictors: log(mu[,2]/mu[,1]), log(mu[,3]/mu[,1])\n## \n## Dispersion Parameter for multinomial family:   1\n## \n## Residual deviance: 1995.605 on 262240 degrees of freedom\n## \n## Log-likelihood: -997.8027 on 262240 degrees of freedom\n## \n## Number of iterations: 18 \n## \n## Reference group is level  1  of the response\n\n\n\n\nAgain, we see that the results are quite similar for this third model.\n\n\nAbsolute risk\n\n\nWe now look at the 2-year risk of relapse:\n\n\nlinearRisk \n- absoluteRisk(object = model1, time = 24, newdata = DT[1:10,])\nlogRisk \n- absoluteRisk(object = model2, time = 24, newdata = DT[1:10,])\nsplineRisk \n- absoluteRisk(object = model3, time = 24, newdata = DT[1:10,])\n\n\n\n\nplot(linearRisk[,1], logRisk[,1],\n     xlab=\nLinear\n, ylab = \nLog/Spline\n, pch=19,\n     xlim=c(0,1), ylim=c(0,1), col='red')\npoints(linearRisk[,1], splineRisk[,1],\n       col = 'blue', pch=19)\nabline(a=0, b=1, lty=2, lwd=2)\nlegend(\ntopleft\n, legend=c(\nLog\n, \nSpline\n),\n       pch=19, col=c(\nred\n, \nblue\n))\n\n\n\n\n\n\nAs we can see, Model 1 and Model 2 give different absolute risk predictions, but the linear and the spline model actually give very similar results. We can also estimate the mean absolute risk for the entire dataset:\n\n\n# The first column corresponds to the event of interest\nmean(linearRisk[,1])\n\n\n\n\n## [1] 0.1958714\n\n\n\n\nmean(logRisk[,1])\n\n\n\n\n## [1] 0.1597606\n\n\n\n\nmean(splineRisk[,1])\n\n\n\n\n## [1] 0.1970028\n\n\n\n\nSession information\n\n\n## R version 3.2.4 Revised (2016-03-16 r70336)\n## Platform: x86_64-pc-linux-gnu (64-bit)\n## Running under: Ubuntu 14.04.4 LTS\n## \n## locale:\n##  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C              \n##  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    \n##  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8   \n##  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n## [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n## \n## attached base packages:\n## [1] splines   stats4    stats     graphics  grDevices utils     datasets \n## [8] methods   base     \n## \n## other attached packages:\n## [1] casebase_0.0.9000 VGAM_1.0-1       \n## \n## loaded via a namespace (and not attached):\n##  [1] Rcpp_0.12.3      knitr_1.12.3     magrittr_1.5     devtools_1.10.0 \n##  [5] munsell_0.4.2    colorspace_1.2-6 R6_2.1.2         httr_1.1.0      \n##  [9] stringr_1.0.0    plyr_1.8.3       tools_3.2.4      grid_3.2.4      \n## [13] data.table_1.9.6 gtable_0.1.2     withr_1.0.1      git2r_0.13.1    \n## [17] htmltools_0.3    yaml_2.1.13      survival_2.38-3  digest_0.6.9    \n## [21] ggplot2_2.0.0    formatR_1.3      codetools_0.2-14 curl_0.9.5      \n## [25] memoise_1.0.0    evaluate_0.8.3   rmarkdown_0.9.5  stringi_1.0-1   \n## [29] scales_0.3.0     chron_2.3-47\n\n\n\n\nReferences", 
            "title": "Competing Risk"
        }, 
        {
            "location": "/competingRisk/#competing-risk-analysis-using-case-base-sampling", 
            "text": "Maxime Turgeon  r Sys.Date()", 
            "title": "Competing risk analysis using case-base sampling"
        }, 
        {
            "location": "/competingRisk/#data", 
            "text": "We will use the same data that was used in Scrucca  et al  [-@scrucca2010regression]. The data is available on the main author's  website .  DT  - read.csv(system.file( extdata ,  bmtcrr.csv , package =  casebase ))\nhead(DT)  ##   Sex   D   Phase Age Status Source  ftime\n## 1   M ALL Relapse  48      2  BM+PB   0.67\n## 2   F AML     CR2  23      1  BM+PB   9.50\n## 3   M ALL     CR3   7      0  BM+PB 131.77\n## 4   F ALL     CR2  26      2  BM+PB  24.03\n## 5   F ALL     CR2  36      2  BM+PB   1.47\n## 6   M ALL Relapse  17      2  BM+PB   2.23  We will perform a competing risk analysis on data from 177 patients who received a stem cell transplant for acute leukemia. The event of interest in relapse, but other competing causes (e.g. transplant-related death) need to be taken into account. We also want to take into account the effect of several covariates such as Sex, Disease (lymphoblastic or myeloblastic leukemia, abbreviated as ALL and AML, respectively), Phase at transplant (Relapse, CR1, CR2, CR3), Source of stem cells (bone marrow and peripheral blood, coded as BM+PB, or peripheral blood, coded as PB), and Age. Below, we reproduce their Table 1:     Variable  Description  Statistical summary      Sex  Sex  M=Male (100)   F=Female (77)    D  Disease  ALL (73)   AML (104)    Phase  Phase  CR1 (47)   CR2 (45)   CR3 (12)   Relapse (73)    Source  Type of transplant  BM+PB (21)   PB (156)    Age  Age of patient (years)  4\u201362   30.47 (13.04)    Ftime  Failure time (months)  0.13\u2013131.77   20.28 (30.78)    Status  Status indicator  0=censored (46)   1=relapse (56)   2=competing event (75)     The statistical summary is generated differently for continuous and categorical variables:     For continuous variables, we are given the range, followed by the mean and standard deviation.    For categorical variables, we are given the counts for each category.    Note that failure time can also correspond to censoring.", 
            "title": "Data"
        }, 
        {
            "location": "/competingRisk/#population-time-plots", 
            "text": "In order to try and visualize the incidence density of relapse, we can look at a population-time plot: on the X-axis we have time, and on the Y-axis we have the size of the risk set at a particular time point. Failure times associated to the event of interest can then be highlighted on the plot using red dots.  nobs  - nrow(DT)\nftime  - DT$ftime\nord  - order(ftime, decreasing=FALSE)\n\n# We split the person-moments in four categories:\n# 1) at-risk\n# 2) main event\n# 3) competing event\n# 4) censored\nyCoords  - cbind(cumsum(DT[ord,  Status ] == 2), \n                 cumsum(DT[ord,  Status ] == 1),\n                 cumsum(DT[ord,  Status ] == 0))\nyCoords  - cbind(yCoords, nobs - rowSums(yCoords))\n\n# Plot only at-risk\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\npolygon(c(0, 0, ftime[ord], max(ftime), 0),\n        c(0, nobs, yCoords[,4], 0, 0), col =  grey90 )\ncases  - DT[,  Status ] == 1\n\n# randomly move the cases vertically\nmoved_cases  - yCoords[cases[ord], 4] * runif(sum(cases))\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col= red , cex=1)     We can right away draw a few conclusions from this plot: first of all, we get a sense of how quickly the size of the risk set changes over time. We also see that the incidence density is non-constant: most relapses occur before 15 months. Finally, we also see that the risk set keeps shrinking after the last event has occured; this could be due to either censoring or the competing event.  To get an idea of whether only relapse is responsible for the shrinking of the risk set in the first few months of follow-up, we can also keep track of how many events have occured at each time point:  # Plot at-risk and events\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\npolygon(c(0,ftime[ord], max(ftime), 0), c(0, yCoords[,2], 0, 0), col =  firebrick3 )\npolygon(c(0, ftime[ord], ftime[rev(ord)], 0, 0),\n        c(0, yCoords[,2], rev(yCoords[,2] + yCoords[,4]), nobs, 0), col =  grey90 )\n\n# randomly move the cases vertically\nmoved_cases  - yCoords[cases[ord], 2] + yCoords[cases[ord], 4] * runif(sum(cases))\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col= red , cex=1)\nlegend( topright , legend=c( Relapse ,  At-risk ), \n       col=c( firebrick3 ,  grey90 ),\n       pch=15)     Therefore, there is also censoring and loss due to competing events happening in the first few months. However, with this plot, we can't differentiate bwetween the two contributions. For this reason we can also keep track of the number of competing events at each time point:  plot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\npolygon(c(0, max(ftime), max(ftime), 0),\n        c(0, 0, nobs, nobs), col =  white )\n# Event of interest\npolygon(c(0,ftime[ord], max(ftime), 0), c(0, yCoords[,2], 0, 0), col =  firebrick3 )\n# Risk set\npolygon(c(0, ftime[ord], ftime[rev(ord)], 0, 0),\n        c(0, yCoords[,2], rev(yCoords[,2] + yCoords[,4]), nobs, 0), col =  grey90 )\n# Competing event\npolygon(c(0, ftime[ord], max(ftime), 0), c(nobs, nobs - yCoords[,1], nobs, nobs), col =  dodgerblue2 )\n\n# randomly move the cases vertically\nmoved_cases  - yCoords[cases[ord], 2] + yCoords[cases[ord], 4] * runif(sum(cases))\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col= red , cex=1)\nlegend( topright , legend=c( Relapse ,  Competing event ,  At-risk ), \n       col=c( firebrick3 ,  dodgerblue2 ,  grey90 ),\n       pch=15)     From this last plot, we can see that there is no censoring during the first 10 months. Moreover, we see that the last competing event occurs around 20 months. Putting all this information together, we have evidence of two types of patients: very sick patients who either relapse or have a competing event early on, and healthier patients who are eventually lost to follow-up.", 
            "title": "Population-time plots"
        }, 
        {
            "location": "/competingRisk/#analysis", 
            "text": "We now turn to the analysis of this dataset. The population-time plots above give evidence of non-constant hazard; therefore, we will explicitely include time in the model. Note that we also include all other variables as possible confounders. First, we include time as a linear term:  library(casebase)\nmodel1  - fitSmoothHazard(Status ~ ftime + Sex + D + Phase + Source + Age, \n                          data = DT, ratio=1000, type =  uniform , time= ftime )\nsummary(model1)  ## \n## Call:\n## vglm(formula = formula, family = multinomial(refLevel = 1), data = sampleData)\n## \n## Pearson residuals:\n##                         Min       1Q   Median        3Q    Max\n## log(mu[,2]/mu[,1]) -0.07345 -0.02205 -0.01239 -0.004704 144.73\n## log(mu[,3]/mu[,1]) -0.10895 -0.02841 -0.01179 -0.002704  63.41\n## \n## Coefficients:\n##                 Estimate Std. Error z value Pr( |z|)    \n## (Intercept):1  -3.474588   0.680663  -5.105 3.31e-07 ***\n## (Intercept):2  -2.549614   0.459171  -5.553 2.81e-08 ***\n## ftime:1        -0.069401   0.014631  -4.744 2.10e-06 ***\n## ftime:2        -0.103346   0.018076  -5.717 1.08e-08 ***\n## SexM:1         -0.293579   0.281057  -1.045  0.29623    \n## SexM:2         -0.408156   0.234223  -1.743  0.08140 .  \n## DAML:1         -0.629272   0.298733  -2.106  0.03516 *  \n## DAML:2         -0.136885   0.274495  -0.499  0.61800    \n## PhaseCR2:1      0.191556   0.465535   0.411  0.68072    \n## PhaseCR2:2      0.290034   0.329955   0.879  0.37940    \n## PhaseCR3:1      0.509231   0.690816   0.737  0.46104    \n## PhaseCR3:2      0.248652   0.523925   0.475  0.63508    \n## PhaseRelapse:1  1.452848   0.390601   3.720  0.00020 ***\n## PhaseRelapse:2  0.779157   0.306387   2.543  0.01099 *  \n## SourcePB:1      0.454649   0.568322   0.800  0.42372    \n## SourcePB:2     -1.079430   0.353163  -3.056  0.00224 ** \n## Age:1          -0.006372   0.011866  -0.537  0.59125    \n## Age:2           0.028030   0.009902   2.831  0.00464 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Number of linear predictors:  2 \n## \n## Names of linear predictors: log(mu[,2]/mu[,1]), log(mu[,3]/mu[,1])\n## \n## Dispersion Parameter for multinomial family:   1\n## \n## Residual deviance: 2009.985 on 262244 degrees of freedom\n## \n## Log-likelihood: -1004.992 on 262244 degrees of freedom\n## \n## Number of iterations: 13 \n## \n## Reference group is level  1  of the response  Because of the results in Turgeon  et al  [-@turgeonCompRisk], the standard errors we obtain from the multinomial logit fit are asymptotically correct, and therefore can be used to construct asymptotic confidence intervals.   From this summary, we see that time is indeed significant, as is Phase (only relapse vs. CR1). Interestingly, we see that the type of disease is only significant for the event of interest, whereas the type of transplant and the age of the patient are only significant for the competing event.  Next, we include the logarithm of time in the model (which leads to a Weibull hazard):  model2  - fitSmoothHazard(Status ~ log(ftime) + Sex + D + Phase + Source + Age, \n                          data = DT, ratio=1000, type =  uniform , time= ftime )\nsummary(model2)  ## \n## Call:\n## vglm(formula = formula, family = multinomial(refLevel = 1), data = sampleData)\n## \n## Pearson residuals:\n##                        Min       1Q   Median       3Q   Max\n## log(mu[,2]/mu[,1]) -0.1723 -0.02169 -0.01484 -0.01120 91.45\n## log(mu[,3]/mu[,1]) -0.2699 -0.02450 -0.01754 -0.01444 69.01\n## \n## Coefficients:\n##                 Estimate Std. Error z value Pr( |z|)    \n## (Intercept):1  -3.931793   0.701633  -5.604 2.10e-08 ***\n## (Intercept):2  -3.043980   0.459504  -6.624 3.48e-11 ***\n## log(ftime):1   -0.326174   0.067934  -4.801 1.58e-06 ***\n## log(ftime):2   -0.405412   0.054786  -7.400 1.36e-13 ***\n## SexM:1         -0.452946   0.291820  -1.552 0.120628    \n## SexM:2         -0.515177   0.239316  -2.153 0.031342 *  \n## DAML:1         -0.682449   0.303771  -2.247 0.024666 *  \n## DAML:2         -0.149322   0.287263  -0.520 0.603197    \n## PhaseCR2:1      0.261893   0.467302   0.560 0.575181    \n## PhaseCR2:2      0.385421   0.329610   1.169 0.242273    \n## PhaseCR3:1      0.438951   0.710562   0.618 0.536738    \n## PhaseCR3:2      0.082495   0.532621   0.155 0.876912    \n## PhaseRelapse:1  1.497704   0.392762   3.813 0.000137 ***\n## PhaseRelapse:2  0.880194   0.307423   2.863 0.004195 ** \n## SourcePB:1      0.651808   0.600985   1.085 0.278114    \n## SourcePB:2     -0.971796   0.368542  -2.637 0.008368 ** \n## Age:1          -0.004476   0.011733  -0.382 0.702822    \n## Age:2           0.027958   0.009871   2.832 0.004620 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Number of linear predictors:  2 \n## \n## Names of linear predictors: log(mu[,2]/mu[,1]), log(mu[,3]/mu[,1])\n## \n## Dispersion Parameter for multinomial family:   1\n## \n## Residual deviance: 2104.931 on 262244 degrees of freedom\n## \n## Log-likelihood: -1052.465 on 262244 degrees of freedom\n## \n## Number of iterations: 11 \n## \n## Reference group is level  1  of the response  As we can see, the results are similar to the ones with a Gompertz hazard, although Sex is now significant for the competing event.  Finally, using splines, we can be quite flexible about the way the hazard depends on time:  model3  - fitSmoothHazard(Status ~ bs(ftime) + Sex + D + Phase + Source + Age, \n                          data = DT, ratio=1000, type =  uniform , time= ftime )\nsummary(model3)  ## \n## Call:\n## vglm(formula = formula, family = multinomial(refLevel = 1), data = sampleData)\n## \n## Pearson residuals:\n##                         Min       1Q    Median         3Q   Max\n## log(mu[,2]/mu[,1]) -0.06477 -0.02234 -0.012758 -2.412e-03 177.3\n## log(mu[,3]/mu[,1]) -0.08998 -0.03014 -0.004554 -2.306e-06 118.6\n## \n## Coefficients:\n##                  Estimate Std. Error z value Pr( |z|)    \n## (Intercept):1   -3.741211   0.704544  -5.310 1.10e-07 ***\n## (Intercept):2   -3.269145   0.506820  -6.450 1.12e-10 ***\n## bs(ftime)1:1     0.007116   2.263182   0.003 0.997491    \n## bs(ftime)1:2     7.001805   3.651896   1.917 0.055199 .  \n## bs(ftime)2:1   -16.189451   8.163262  -1.983 0.047344 *  \n## bs(ftime)2:2   -77.534046  25.577967  -3.031 0.002435 ** \n## bs(ftime)3:1    -2.417463  10.211989  -0.237 0.812868    \n## bs(ftime)3:2    -2.437630  22.304549  -0.109 0.912974    \n## SexM:1          -0.287843   0.282408  -1.019 0.308086    \n## SexM:2          -0.402536   0.235158  -1.712 0.086939 .  \n## DAML:1          -0.632579   0.299835  -2.110 0.034879 *  \n## DAML:2          -0.163313   0.273080  -0.598 0.549813    \n## PhaseCR2:1       0.159591   0.465919   0.343 0.731953    \n## PhaseCR2:2       0.292454   0.330122   0.886 0.375673    \n## PhaseCR3:1       0.523730   0.693387   0.755 0.450056    \n## PhaseCR3:2       0.261503   0.524775   0.498 0.618262    \n## PhaseRelapse:1   1.476824   0.394558   3.743 0.000182 ***\n## PhaseRelapse:2   0.877603   0.310625   2.825 0.004724 ** \n## SourcePB:1       0.431423   0.572585   0.753 0.451170    \n## SourcePB:2      -1.131722   0.356749  -3.172 0.001512 ** \n## Age:1           -0.004786   0.012043  -0.397 0.691044    \n## Age:2            0.030841   0.010086   3.058 0.002229 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Number of linear predictors:  2 \n## \n## Names of linear predictors: log(mu[,2]/mu[,1]), log(mu[,3]/mu[,1])\n## \n## Dispersion Parameter for multinomial family:   1\n## \n## Residual deviance: 1995.605 on 262240 degrees of freedom\n## \n## Log-likelihood: -997.8027 on 262240 degrees of freedom\n## \n## Number of iterations: 18 \n## \n## Reference group is level  1  of the response  Again, we see that the results are quite similar for this third model.  Absolute risk  We now look at the 2-year risk of relapse:  linearRisk  - absoluteRisk(object = model1, time = 24, newdata = DT[1:10,])\nlogRisk  - absoluteRisk(object = model2, time = 24, newdata = DT[1:10,])\nsplineRisk  - absoluteRisk(object = model3, time = 24, newdata = DT[1:10,])  plot(linearRisk[,1], logRisk[,1],\n     xlab= Linear , ylab =  Log/Spline , pch=19,\n     xlim=c(0,1), ylim=c(0,1), col='red')\npoints(linearRisk[,1], splineRisk[,1],\n       col = 'blue', pch=19)\nabline(a=0, b=1, lty=2, lwd=2)\nlegend( topleft , legend=c( Log ,  Spline ),\n       pch=19, col=c( red ,  blue ))   As we can see, Model 1 and Model 2 give different absolute risk predictions, but the linear and the spline model actually give very similar results. We can also estimate the mean absolute risk for the entire dataset:  # The first column corresponds to the event of interest\nmean(linearRisk[,1])  ## [1] 0.1958714  mean(logRisk[,1])  ## [1] 0.1597606  mean(splineRisk[,1])  ## [1] 0.1970028", 
            "title": "Analysis"
        }, 
        {
            "location": "/competingRisk/#session-information", 
            "text": "## R version 3.2.4 Revised (2016-03-16 r70336)\n## Platform: x86_64-pc-linux-gnu (64-bit)\n## Running under: Ubuntu 14.04.4 LTS\n## \n## locale:\n##  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C              \n##  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    \n##  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8   \n##  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n## [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n## \n## attached base packages:\n## [1] splines   stats4    stats     graphics  grDevices utils     datasets \n## [8] methods   base     \n## \n## other attached packages:\n## [1] casebase_0.0.9000 VGAM_1.0-1       \n## \n## loaded via a namespace (and not attached):\n##  [1] Rcpp_0.12.3      knitr_1.12.3     magrittr_1.5     devtools_1.10.0 \n##  [5] munsell_0.4.2    colorspace_1.2-6 R6_2.1.2         httr_1.1.0      \n##  [9] stringr_1.0.0    plyr_1.8.3       tools_3.2.4      grid_3.2.4      \n## [13] data.table_1.9.6 gtable_0.1.2     withr_1.0.1      git2r_0.13.1    \n## [17] htmltools_0.3    yaml_2.1.13      survival_2.38-3  digest_0.6.9    \n## [21] ggplot2_2.0.0    formatR_1.3      codetools_0.2-14 curl_0.9.5      \n## [25] memoise_1.0.0    evaluate_0.8.3   rmarkdown_0.9.5  stringi_1.0-1   \n## [29] scales_0.3.0     chron_2.3-47", 
            "title": "Session information"
        }, 
        {
            "location": "/competingRisk/#references", 
            "text": "", 
            "title": "References"
        }, 
        {
            "location": "/popTime/", 
            "text": "Casebase Vignette\n\n\nSahir R. Bhatnagar\n\n\nr Sys.Date()\n  \n\n\nLoad Required Packages\n\n\nlibrary(knitr)\nlibrary(data.table)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(survival)\nlibrary(casebase) \n\n\n\n\nIntroduction\n\n\n \n\n\n \n\n\n \n\n\n \n\n\nSample Code\n\n\n# set seed for reproducibility\nset.seed(123456)\n\n# read in the data. This is the data from 177 patients who received \n# a stem cell transplant for acute leukemia. It is the same data show \n# in Example 2 below\nDT \n- read.csv(\nhttps://raw.githubusercontent.com/sahirbhatnagar/casebase/master/inst/extdata/bmtcrr.csv\n)\n\n# data structure\nstr(DT)\n\n\n\n\n## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels \nF\n,\nM\n: 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \nALL\n,\nAML\n: 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels \nCR1\n,\nCR2\n,\nCR3\n,..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \nBM+PB\n,\nPB\n: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...\n\n\n\n\n# follow-up time\nftime \n- DT$ftime\n\n# get the indices of the individuals in order such that\n# the ones with the shortest follow up time have a higher \n# y-coordinate\nord \n- order(ftime, decreasing = FALSE)\n\n# We split the person-moments in four categories:\n# 1) at-risk\n# 2) main event\n# 3) competing event\n# 4) censored\nyCoords \n- cbind(competing = cumsum(DT[ord, \nStatus\n] == 2), \n                 event = cumsum(DT[ord, \nStatus\n] == 1),\n                 censored = cumsum(DT[ord, \nStatus\n] == 0))\n\nyCoords \n- cbind(yCoords, atRisk = nobs - rowSums(yCoords))\n\nhead(yCoords, n = 20)\n\n\n\n\n##       competing event censored atRisk\n##  [1,]         1     0        0    176\n##  [2,]         2     0        0    175\n##  [3,]         3     0        0    174\n##  [4,]         4     0        0    173\n##  [5,]         5     0        0    172\n##  [6,]         6     0        0    171\n##  [7,]         7     0        0    170\n##  [8,]         8     0        0    169\n##  [9,]         9     0        0    168\n## [10,]         9     1        0    167\n## [11,]         9     2        0    166\n## [12,]         9     3        0    165\n## [13,]        10     3        0    164\n## [14,]        10     4        0    163\n## [15,]        11     4        0    162\n## [16,]        12     4        0    161\n## [17,]        13     4        0    160\n## [18,]        13     5        0    159\n## [19,]        13     6        0    158\n## [20,]        14     6        0    157\n\n\n\n\n# Plot only at-risk\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')\n\n\n\n\n \n\n\npolygon(c(0, 0, ftime[ord], max(ftime), 0),\n        c(0, nobs, yCoords[,\natRisk\n], 0, 0), col = \ngrey90\n)\n\n\n\n\n \n\n\ncases \n- DT[, \nStatus\n] == 1\n\n# randomly move the cases vertically\nmoved_cases \n- yCoords[cases[ord], 4] * runif(sum(cases))\n\n# only plot cases as red dots in proper order on the x-axis\n# but randomly on the y-axis from available risk set\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col=\nred\n, cex=1)\n\n\n\n\n \n\n\n1. Veteran Data\n\n\n# veteran data in library(survival)\ndata(\nveteran\n)\nstr(veteran)\n\n\n\n\n## 'data.frame':    137 obs. of  8 variables:\n##  $ trt     : num  1 1 1 1 1 1 1 1 1 1 ...\n##  $ celltype: Factor w/ 4 levels \nsquamous\n,\nsmallcell\n,..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ time    : num  72 411 228 126 118 10 82 110 314 100 ...\n##  $ status  : num  1 1 1 1 1 1 1 1 1 0 ...\n##  $ karno   : num  60 70 60 60 70 20 40 80 50 70 ...\n##  $ diagtime: num  7 5 3 9 11 5 10 29 18 6 ...\n##  $ age     : num  69 64 38 63 65 49 69 68 43 70 ...\n##  $ prior   : num  0 10 0 10 10 0 10 0 0 0 ...\n\n\n\n\n# create 'popTime' object\npopTimeData \n- popTime(data = veteran)\n\n\n\n\n## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\n# object of class 'popTime'\nclass(popTimeData)\n\n\n\n\n## [1] \npopTime\n    \ndata.table\n \ndata.frame\n\n\n\n\n\n# plot method for objects of class 'popTime'\nplot(popTimeData)\n\n\n\n\n \n\n\nStratified by treatment population time plot\n\n\n# stratified by treatment population time plot\nveteran \n- transform(veteran, trt = factor(trt, levels = 1:2,\n                                           labels = c(\nstandard\n, \ntest\n)))\n\n# create 'popTimeExposure' object\npopTimeData \n- popTime(data = veteran, exposure = \ntrt\n)\n\n\n\n\n## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\n# object of class 'popTimeExposure'\nclass(popTimeData)\n\n\n\n\n## [1] \npopTimeExposure\n \nlist\n\n\n\n\n\n# plot method for objects of class 'popTimeExposure'\nplot(popTimeData)\n\n\n\n\n \n\n\n2. Stem Cell Data\n\n\nbmt \n- read.csv(\nhttps://raw.githubusercontent.com/sahirbhatnagar/casebase/master/inst/extdata/bmtcrr.csv\n)\nstr(bmt)\n\n\n\n\n## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels \nF\n,\nM\n: 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \nALL\n,\nAML\n: 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels \nCR1\n,\nCR2\n,\nCR3\n,..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \nBM+PB\n,\nPB\n: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...\n\n\n\n\n# create 'popTime' object\npopTimeData \n- popTime(data = bmt, time = \nftime\n)\n\n\n\n\n## [1] 'Status' will be used as the event variable\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\n# object of class 'popTime'\nclass(popTimeData)\n\n\n\n\n## [1] \npopTime\n    \ndata.table\n \ndata.frame\n\n\n\n\n\n# plot method for objects of class 'popTime'\nplot(popTimeData)\n\n\n\n\n \n\n\nStratified by Disease\n\n\n# stratified by Disease population time plot\n# Disease (lymphoblastic or myeloblastic leukemia,\n# abbreviated as ALL and AML, respectively)\n\n# create 'popTimeExposure' object\npopTimeData \n- popTime(data = bmt, time = \nftime\n, exposure = \nD\n)\n\n\n\n\n## [1] 'Status' will be used as the event variable\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\n# object of class 'popTimeExposure'\nclass(popTimeData)\n\n\n\n\n## [1] \npopTimeExposure\n \nlist\n\n\n\n\n\n# plot method for objects of class 'popTimeExposure'\nplot(popTimeData)\n\n\n\n\n \n\n\n# stratify by gender\npopTimeData \n- popTime(data = bmt, time = \nftime\n, exposure = \nSex\n)\n\n\n\n\n## [1] 'Status' will be used as the event variable\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\nplot(popTimeData)\n\n\n\n\n \n\n\n3. Stanford Heart Transplant Data\n\n\n# data from library(survival)\ndata(\nheart\n)\nstr(heart)\n\n\n\n\n## 'data.frame':    172 obs. of  8 variables:\n##  $ start     : num  0 0 0 1 0 36 0 0 0 51 ...\n##  $ stop      : num  50 6 1 16 36 39 18 3 51 675 ...\n##  $ event     : num  1 1 0 1 0 1 1 1 0 1 ...\n##  $ age       : num  -17.16 3.84 6.3 6.3 -7.74 ...\n##  $ year      : num  0.123 0.255 0.266 0.266 0.49 ...\n##  $ surgery   : num  0 0 0 0 0 0 0 0 0 0 ...\n##  $ transplant: Factor w/ 2 levels \n0\n,\n1\n: 1 1 1 2 1 2 1 1 1 2 ...\n##  $ id        : num  1 2 3 3 4 4 5 6 7 7 ...\n\n\n\n\n# create time variable for time in study\nheart \n- transform(heart,\n                   time = stop - start,\n                   transplant = factor(transplant,\n                                       labels = c(\nno transplant\n, \ntransplant\n)))\n\n# stratify by transplant indicator\npopTimeData \n- popTime(data = heart, exposure = \ntransplant\n)\n\n\n\n\n## [1] 'time' will be used as the time variable\n## [1] 'event' will be used as the event variable\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling only from individuals who never experienced\n##                     the event of interest\n\n\n\n\n# can specify a legend\nplot(popTimeData, legend = TRUE)\n\n\n\n\n \n\n\n4. NCCTG Lung Cancer Data\n\n\n# data from library(survival)\ndata(\ncancer\n)\nstr(cancer)\n\n\n\n\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...\n\n\n\n\n# since the event indicator 'status' is numeric, it must have\n# 0 for censored and 1 for event\ncancer \n- transform(cancer,\n                    status = status - 1,\n                    sex = factor(sex, levels = 1:2,\n                                 labels = c(\nMale\n, \nFemale\n)))\n\n\n# population time plot\n# redistributing the red points among those who never experienced an event\n# because there are enough available at each time point\npopTimeData \n- popTime(data = cancer)\n\n\n\n\n## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable\n\n\n\n\n## Sampling only from individuals who never experienced\n##                     the event of interest\n\n\n\n\nplot(popTimeData)\n\n\n\n\n \n\n\nStratified by gender\n\n\npopTimeData \n- popTime(data = cancer, exposure = \nsex\n)\n\n\n\n\n## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable\n\n\n\n\n## Sampling only from individuals who never experienced\n##                     the event of interest\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\n# can change the plot aesthetics\nplot(popTimeData,\n     line.width = 0.2, line.colour = \nblack\n,\n     point.size = 1, point.colour = \ncyan\n)\n\n\n\n\n \n\n\n5. Simulated Data Example\n\n\nSimulate the data\n\n\nset.seed(1)\nnobs \n- 5000\n\n# simulation parameters\na1 \n- 1.0\nb1 \n- 200\na2 \n- 1.0\nb2 \n- 50\nc1 \n- 0.0\nc2 \n- 0.0\n\n# end of study time\neost \n- 10\n\n# e event type 0-censored, 1-event of interest, 2-competing event\n# t observed time/endpoint\n# z is a binary covariate\nDTsim \n- data.table(ID = seq_len(nobs), z=rbinom(nobs, 1, 0.5))\nsetkey(DTsim, ID)\nDTsim[,`:=` (event_time = rweibull(nobs, a1, b1 * exp(z * c1)^(-1/a1)),\n             competing_time = rweibull(nobs, a2, b2 * exp(z * c2)^(-1/a2)),\n             end_of_study_time = eost)]\nDTsim[,`:=`(event = 1 * (event_time \n competing_time) +\n                2 * (event_time \n= competing_time),\n            time = pmin(event_time, competing_time))]\nDTsim[time \n= end_of_study_time, event := 0]\nDTsim[time \n= end_of_study_time, time:=end_of_study_time]\n\n\n\n\nPopulation Time Plot\n\n\n# create 'popTime' object\npopTimeData \n- popTime(data = DTsim, time = \ntime\n, event = \nevent\n)\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\nplot(popTimeData)\n\n\n\n\n \n\n\nStratified by Binary Covariate z\n\n\n# stratified by binary covariate z\npopTimeData \n- popTime(data = DTsim, time = \ntime\n, event = \nevent\n, exposure = \nz\n)\n\n\n\n\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status\n\n\n\n\n# we can line up the plots side-by-side instead of one on top of the other\nplot(popTimeData, ncol = 2)", 
            "title": "Population Time Plots"
        }, 
        {
            "location": "/popTime/#casebase-vignette", 
            "text": "Sahir R. Bhatnagar  r Sys.Date()", 
            "title": "Casebase Vignette"
        }, 
        {
            "location": "/popTime/#load-required-packages", 
            "text": "library(knitr)\nlibrary(data.table)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(survival)\nlibrary(casebase)", 
            "title": "Load Required Packages"
        }, 
        {
            "location": "/popTime/#introduction", 
            "text": "", 
            "title": "Introduction"
        }, 
        {
            "location": "/popTime/#sample-code", 
            "text": "# set seed for reproducibility\nset.seed(123456)\n\n# read in the data. This is the data from 177 patients who received \n# a stem cell transplant for acute leukemia. It is the same data show \n# in Example 2 below\nDT  - read.csv( https://raw.githubusercontent.com/sahirbhatnagar/casebase/master/inst/extdata/bmtcrr.csv )\n\n# data structure\nstr(DT)  ## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels  F , M : 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels  ALL , AML : 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels  CR1 , CR2 , CR3 ,..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels  BM+PB , PB : 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...  # follow-up time\nftime  - DT$ftime\n\n# get the indices of the individuals in order such that\n# the ones with the shortest follow up time have a higher \n# y-coordinate\nord  - order(ftime, decreasing = FALSE)\n\n# We split the person-moments in four categories:\n# 1) at-risk\n# 2) main event\n# 3) competing event\n# 4) censored\nyCoords  - cbind(competing = cumsum(DT[ord,  Status ] == 2), \n                 event = cumsum(DT[ord,  Status ] == 1),\n                 censored = cumsum(DT[ord,  Status ] == 0))\n\nyCoords  - cbind(yCoords, atRisk = nobs - rowSums(yCoords))\n\nhead(yCoords, n = 20)  ##       competing event censored atRisk\n##  [1,]         1     0        0    176\n##  [2,]         2     0        0    175\n##  [3,]         3     0        0    174\n##  [4,]         4     0        0    173\n##  [5,]         5     0        0    172\n##  [6,]         6     0        0    171\n##  [7,]         7     0        0    170\n##  [8,]         8     0        0    169\n##  [9,]         9     0        0    168\n## [10,]         9     1        0    167\n## [11,]         9     2        0    166\n## [12,]         9     3        0    165\n## [13,]        10     3        0    164\n## [14,]        10     4        0    163\n## [15,]        11     4        0    162\n## [16,]        12     4        0    161\n## [17,]        13     4        0    160\n## [18,]        13     5        0    159\n## [19,]        13     6        0    158\n## [20,]        14     6        0    157  # Plot only at-risk\nplot(0, type='n', xlim=c(0, max(ftime)), ylim=c(0, nobs), \n     xlab='Follow-up time', ylab='Population')     polygon(c(0, 0, ftime[ord], max(ftime), 0),\n        c(0, nobs, yCoords[, atRisk ], 0, 0), col =  grey90 )     cases  - DT[,  Status ] == 1\n\n# randomly move the cases vertically\nmoved_cases  - yCoords[cases[ord], 4] * runif(sum(cases))\n\n# only plot cases as red dots in proper order on the x-axis\n# but randomly on the y-axis from available risk set\npoints((ftime[ord])[cases[ord]], moved_cases, pch=20, col= red , cex=1)", 
            "title": "Sample Code"
        }, 
        {
            "location": "/popTime/#1-veteran-data", 
            "text": "# veteran data in library(survival)\ndata( veteran )\nstr(veteran)  ## 'data.frame':    137 obs. of  8 variables:\n##  $ trt     : num  1 1 1 1 1 1 1 1 1 1 ...\n##  $ celltype: Factor w/ 4 levels  squamous , smallcell ,..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ time    : num  72 411 228 126 118 10 82 110 314 100 ...\n##  $ status  : num  1 1 1 1 1 1 1 1 1 0 ...\n##  $ karno   : num  60 70 60 60 70 20 40 80 50 70 ...\n##  $ diagtime: num  7 5 3 9 11 5 10 29 18 6 ...\n##  $ age     : num  69 64 38 63 65 49 69 68 43 70 ...\n##  $ prior   : num  0 10 0 10 10 0 10 0 0 0 ...  # create 'popTime' object\npopTimeData  - popTime(data = veteran)  ## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable  ## Sampling from all remaining individuals under study,\n##                     regardless of event status  # object of class 'popTime'\nclass(popTimeData)  ## [1]  popTime      data.table   data.frame   # plot method for objects of class 'popTime'\nplot(popTimeData)", 
            "title": "1. Veteran Data"
        }, 
        {
            "location": "/popTime/#stratified-by-treatment-population-time-plot", 
            "text": "# stratified by treatment population time plot\nveteran  - transform(veteran, trt = factor(trt, levels = 1:2,\n                                           labels = c( standard ,  test )))\n\n# create 'popTimeExposure' object\npopTimeData  - popTime(data = veteran, exposure =  trt )  ## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable  ## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status  # object of class 'popTimeExposure'\nclass(popTimeData)  ## [1]  popTimeExposure   list   # plot method for objects of class 'popTimeExposure'\nplot(popTimeData)", 
            "title": "Stratified by treatment population time plot"
        }, 
        {
            "location": "/popTime/#2-stem-cell-data", 
            "text": "bmt  - read.csv( https://raw.githubusercontent.com/sahirbhatnagar/casebase/master/inst/extdata/bmtcrr.csv )\nstr(bmt)  ## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels  F , M : 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels  ALL , AML : 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels  CR1 , CR2 , CR3 ,..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels  BM+PB , PB : 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...  # create 'popTime' object\npopTimeData  - popTime(data = bmt, time =  ftime )  ## [1] 'Status' will be used as the event variable  ## Sampling from all remaining individuals under study,\n##                     regardless of event status  # object of class 'popTime'\nclass(popTimeData)  ## [1]  popTime      data.table   data.frame   # plot method for objects of class 'popTime'\nplot(popTimeData)", 
            "title": "2. Stem Cell Data"
        }, 
        {
            "location": "/popTime/#stratified-by-disease", 
            "text": "# stratified by Disease population time plot\n# Disease (lymphoblastic or myeloblastic leukemia,\n# abbreviated as ALL and AML, respectively)\n\n# create 'popTimeExposure' object\npopTimeData  - popTime(data = bmt, time =  ftime , exposure =  D )  ## [1] 'Status' will be used as the event variable  ## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status  # object of class 'popTimeExposure'\nclass(popTimeData)  ## [1]  popTimeExposure   list   # plot method for objects of class 'popTimeExposure'\nplot(popTimeData)     # stratify by gender\npopTimeData  - popTime(data = bmt, time =  ftime , exposure =  Sex )  ## [1] 'Status' will be used as the event variable  ## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status  plot(popTimeData)", 
            "title": "Stratified by Disease"
        }, 
        {
            "location": "/popTime/#3-stanford-heart-transplant-data", 
            "text": "# data from library(survival)\ndata( heart )\nstr(heart)  ## 'data.frame':    172 obs. of  8 variables:\n##  $ start     : num  0 0 0 1 0 36 0 0 0 51 ...\n##  $ stop      : num  50 6 1 16 36 39 18 3 51 675 ...\n##  $ event     : num  1 1 0 1 0 1 1 1 0 1 ...\n##  $ age       : num  -17.16 3.84 6.3 6.3 -7.74 ...\n##  $ year      : num  0.123 0.255 0.266 0.266 0.49 ...\n##  $ surgery   : num  0 0 0 0 0 0 0 0 0 0 ...\n##  $ transplant: Factor w/ 2 levels  0 , 1 : 1 1 1 2 1 2 1 1 1 2 ...\n##  $ id        : num  1 2 3 3 4 4 5 6 7 7 ...  # create time variable for time in study\nheart  - transform(heart,\n                   time = stop - start,\n                   transplant = factor(transplant,\n                                       labels = c( no transplant ,  transplant )))\n\n# stratify by transplant indicator\npopTimeData  - popTime(data = heart, exposure =  transplant )  ## [1] 'time' will be used as the time variable\n## [1] 'event' will be used as the event variable  ## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling only from individuals who never experienced\n##                     the event of interest  # can specify a legend\nplot(popTimeData, legend = TRUE)", 
            "title": "3. Stanford Heart Transplant Data"
        }, 
        {
            "location": "/popTime/#4-ncctg-lung-cancer-data", 
            "text": "# data from library(survival)\ndata( cancer )\nstr(cancer)  ## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...  # since the event indicator 'status' is numeric, it must have\n# 0 for censored and 1 for event\ncancer  - transform(cancer,\n                    status = status - 1,\n                    sex = factor(sex, levels = 1:2,\n                                 labels = c( Male ,  Female )))\n\n\n# population time plot\n# redistributing the red points among those who never experienced an event\n# because there are enough available at each time point\npopTimeData  - popTime(data = cancer)  ## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable  ## Sampling only from individuals who never experienced\n##                     the event of interest  plot(popTimeData)", 
            "title": "4. NCCTG Lung Cancer Data"
        }, 
        {
            "location": "/popTime/#stratified-by-gender", 
            "text": "popTimeData  - popTime(data = cancer, exposure =  sex )  ## [1] 'time' will be used as the time variable\n## [1] 'status' will be used as the event variable  ## Sampling only from individuals who never experienced\n##                     the event of interest\n## Sampling from all remaining individuals under study,\n##                     regardless of event status  # can change the plot aesthetics\nplot(popTimeData,\n     line.width = 0.2, line.colour =  black ,\n     point.size = 1, point.colour =  cyan )", 
            "title": "Stratified by gender"
        }, 
        {
            "location": "/popTime/#5-simulated-data-example", 
            "text": "", 
            "title": "5. Simulated Data Example"
        }, 
        {
            "location": "/popTime/#simulate-the-data", 
            "text": "set.seed(1)\nnobs  - 5000\n\n# simulation parameters\na1  - 1.0\nb1  - 200\na2  - 1.0\nb2  - 50\nc1  - 0.0\nc2  - 0.0\n\n# end of study time\neost  - 10\n\n# e event type 0-censored, 1-event of interest, 2-competing event\n# t observed time/endpoint\n# z is a binary covariate\nDTsim  - data.table(ID = seq_len(nobs), z=rbinom(nobs, 1, 0.5))\nsetkey(DTsim, ID)\nDTsim[,`:=` (event_time = rweibull(nobs, a1, b1 * exp(z * c1)^(-1/a1)),\n             competing_time = rweibull(nobs, a2, b2 * exp(z * c2)^(-1/a2)),\n             end_of_study_time = eost)]\nDTsim[,`:=`(event = 1 * (event_time   competing_time) +\n                2 * (event_time  = competing_time),\n            time = pmin(event_time, competing_time))]\nDTsim[time  = end_of_study_time, event := 0]\nDTsim[time  = end_of_study_time, time:=end_of_study_time]", 
            "title": "Simulate the data"
        }, 
        {
            "location": "/popTime/#population-time-plot", 
            "text": "# create 'popTime' object\npopTimeData  - popTime(data = DTsim, time =  time , event =  event )  ## Sampling from all remaining individuals under study,\n##                     regardless of event status  plot(popTimeData)", 
            "title": "Population Time Plot"
        }, 
        {
            "location": "/popTime/#stratified-by-binary-covariate-z", 
            "text": "# stratified by binary covariate z\npopTimeData  - popTime(data = DTsim, time =  time , event =  event , exposure =  z )  ## Sampling from all remaining individuals under study,\n##                     regardless of event status\n## Sampling from all remaining individuals under study,\n##                     regardless of event status  # we can line up the plots side-by-side instead of one on top of the other\nplot(popTimeData, ncol = 2)", 
            "title": "Stratified by Binary Covariate z"
        }, 
        {
            "location": "/references/", 
            "text": "References\n\n\n\n\n\n\nEfron, Bradley. 1977. \"The Efficiency of Cox's Likelihood Function for Censored Data.\" \nJournal of the American Statistical Association\n 72 (359). Taylor \n Francis Group: 557\u201365.\n\n\n\n\n\n\nHanley, James A, and Olli S Miettinen. 2009. \"Fitting Smooth-in-Time Prognostic Risk Functions via Logistic Regression.\" \nThe International Journal of Biostatistics\n 5 (1).\n\n\n\n\n\n\nMantel, Nathan. 1973. \"Synthetic Retrospective Studies and Related Topics.\" \nBiometrics\n. JSTOR, 479\u201386.\n\n\n\n\n\n\nSaarela, Olli. 2015. \"A Case-Base Sampling Method for Estimating Recurrent Event Intensities.\" \nLifetime Data Analysis\n. Springer, 1\u201317.\n\n\n\n\n\n\nSaarela, Olli, and Elja Arjas. 2015. \"Non-Parametric Bayesian Hazard Regression for Chronic Disease Risk Assessment.\" \nScandinavian Journal of Statistics\n 42 (2). Wiley Online Library: 609\u201326.\n\n\n\n\n\n\nScrucca, L, A Santucci, and F Aversa. 2010. \"Regression Modeling of Competing Risk Using R: An in Depth Guide for Clinicians.\" \nBone Marrow Transplantation\n 45 (9). Nature Publishing Group: 1388\u201395.", 
            "title": "References"
        }, 
        {
            "location": "/references/#references", 
            "text": "Efron, Bradley. 1977. \"The Efficiency of Cox's Likelihood Function for Censored Data.\"  Journal of the American Statistical Association  72 (359). Taylor   Francis Group: 557\u201365.    Hanley, James A, and Olli S Miettinen. 2009. \"Fitting Smooth-in-Time Prognostic Risk Functions via Logistic Regression.\"  The International Journal of Biostatistics  5 (1).    Mantel, Nathan. 1973. \"Synthetic Retrospective Studies and Related Topics.\"  Biometrics . JSTOR, 479\u201386.    Saarela, Olli. 2015. \"A Case-Base Sampling Method for Estimating Recurrent Event Intensities.\"  Lifetime Data Analysis . Springer, 1\u201317.    Saarela, Olli, and Elja Arjas. 2015. \"Non-Parametric Bayesian Hazard Regression for Chronic Disease Risk Assessment.\"  Scandinavian Journal of Statistics  42 (2). Wiley Online Library: 609\u201326.    Scrucca, L, A Santucci, and F Aversa. 2010. \"Regression Modeling of Competing Risk Using R: An in Depth Guide for Clinicians.\"  Bone Marrow Transplantation  45 (9). Nature Publishing Group: 1388\u201395.", 
            "title": "References"
        }
    ]
}